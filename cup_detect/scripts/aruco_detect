#!/usr/bin/env python
from numpy.lib.function_base import average
import cv2
import numpy as np
import rospy
from tf import transformations
from tf2_ros import TransformBroadcaster
from cv_bridge import CvBridge, CvBridgeError
from sensor_msgs.msg import Image
from geometry_msgs.msg import Pose, TransformStamped
from math import pi

class ArucoDetect:
  def __init__(self, robot_id, cup_id):

    #create cv bridge instance
    self.cvBridge = CvBridge()

    #create  camera_subscriber
    self.image_sub = rospy.Subscriber('/image', Image, self.image_callback)

    # create tfBroadcaster
    self.tfBroadcaster = TransformBroadcaster()
    
    #create bounding box image pub
    self.bounding_image_pub = rospy.Publisher('/bounding_image', Image, queue_size=1)
    self.cup_tvecs_list = np.empty([1,3])
    self.cup_rvecs_list = np.empty([1,3])
    self.robot_rvecs_list = np.empty([1,3])
    self.robot_tvecs_list = np.empty([1   ,3])

    #load aruco marker dictionary
    self.aruco_dict = cv2.aruco.Dictionary_get(cv2.aruco.DICT_6X6_100)
    # this value should match the last value in the dictionary if predefined.
    # otherwise if a custom size is used generate a new dictionary
    #this unit is in metres
    self.marker_size = 0.1

    #create aruco params
    self.aruco_param = cv2.aruco.DetectorParameters_create()

    # TODO offload paramaters to be obtained on ros network
    self.cam_matrix_1080 = np.array([[  1997.44065,    0.,          938.99262],[   0.,          1996.92577,  572.39607],[   0.,            0.,            1.,        ]])
    self.dist_480 = np.array([[  0.09345,   -0.09263,   -0.00033,   0.00435,  0.00000]])

    self.cam_matrix_480 = np.array([[  658.02788,    0.,          328.23101],[   0.,          657.60186,  256.33508],[   0.,            0.,            1.,        ]])
    self.dist_1080 = np.array([[  -0.08224,   2.96513,   -0.00730,   -0.00196,  0.00000]])

    # init id variables
    self.cup_id = cup_id
    self.robot_id = robot_id


  def image_callback(self, msg):
    # try to convert image to cv
    try:
      cv_image = cv2.flip(cv2.flip(self.cvBridge.imgmsg_to_cv2(msg),1),0)

      # convert image to graysecale
      # gs_image = cv2.cvtColor(cv_image, cv2.COLOR_BGR2RGB)
      # cv2.imshow('cunt', gs_image)
      # cv2.waitKey(1)
      
      # detect markers in vision
      bounding_boxes, ids, _ = cv2.aruco.detectMarkers(cv_image, self.aruco_dict, parameters=self.aruco_param)
      
      # publish image with detected markers for debugging
      cv2.aruco.drawDetectedMarkers(cv_image, bounding_boxes)

      # check if the required AR Tags can be seen once
      if (len(np.where(ids == self.cup_id)[0]) == 1) and (len(np.where(ids == self.robot_id)[0]) == 1):

        # get index value of robot
        index_of_robot = np.where(ids==self.robot_id)[0][0]

        #get index value of cup
        index_of_cup = np.where(ids==self.cup_id)[0][0]

        # limit to important bounding boxes
        important_bounding_boxes = [bounding_boxes[index_of_cup], bounding_boxes[index_of_robot]]
        ids = [index_of_cup, index_of_robot]

        # Determine marker poses
        [rvecs, tvecs] = cv2.aruco.estimatePoseSingleMarkers(important_bounding_boxes, self.marker_size, self.cam_matrix_1080, self.dist_1080)

        cup_tvec = tvecs[0]
        cup_rvec = rvecs[0]
        robot_tvec = tvecs[1]
        robot_rvec = rvecs[1]

        print(cup_rvec)

        self.cup_tvecs_list = np.append(self.cup_tvecs_list, cup_tvec, axis=0)
        self.cup_rvecs_list = np.append(self.cup_rvecs_list, cup_rvec, axis=0)
        self.robot_tvecs_list = np.append(self.robot_tvecs_list, robot_tvec, axis=0)
        self.robot_rvecs_list = np.append(self.robot_rvecs_list, robot_rvec, axis=0)
        if np.size(self.cup_tvecs_list, axis = 0) > 10:
          self.cup_tvecs_list = np.delete(self.cup_tvecs_list, (0), axis=0)
          self.cup_rvecs_list = np.delete(self.cup_rvecs_list, (0), axis=0)
          self.robot_tvecs_list = np.delete(self.robot_tvecs_list, (0), axis=0)
          self.robot_rvecs_list = np.delete(self.robot_rvecs_list, (0), axis=0)

          # here there is always 10 elements in the array
          # average the x



          
          cup_tvec = np.mean(self.cup_tvecs_list, axis=0)
          cup_rvec = np.mean(self.cup_rvecs_list, axis=0)
          robot_tvec = np.mean(self.robot_tvecs_list, axis=0)
          robot_rvec = np.mean(self.robot_rvecs_list, axis=0)

        cv2.aruco.drawAxis(cv_image, self.cam_matrix_1080, self.dist_1080, cup_rvec, cup_tvec, 0.1)  # Draw axis
        cv2.aruco.drawAxis(cv_image, self.cam_matrix_1080, self.dist_1080, robot_rvec, robot_tvec, 0.1)  # Draw axis

        try:
          img_msg = self.cvBridge.cv2_to_imgmsg(cv_image, 'bgr8')
          self.bounding_image_pub.publish(img_msg)
        except CvBridgeError:
          print('failed to convert cv2 image to ros message')

        # print('tvec ', robot_tvec, 'rvec', robot_rvec)

        # broadcast tf from camera frame to cup_ar_tag
        #TODO check that rotation and translation values are being set to correct axis
        # cup_ar_transform = TransformStamped()
        # cup_ar_transform.header.stamp = rospy.Time.now()
        # cup_ar_transform.header.frame_id = msg.header.frame_id
        # cup_ar_transform.child_frame_id = "cup_ar_marker"
        # cup_ar_transform.transform.translation.x = cup_tvec[1]
        # cup_ar_transform.transform.translation.y = cup_tvec[0]
        # cup_ar_transform.transform.translation.z = cup_tvec[2]
        # q = transformations.quaternion_from_euler(cup_rvec[0], cup_rvec[1], cup_rvec[2])
        # cup_ar_transform.transform.rotation.x = q[0]
        # cup_ar_transform.transform.rotation.y = q[1]
        # cup_ar_transform.transform.rotation.z = q[2]
        # cup_ar_transform.transform.rotation.w = q[3]
        # self.tfBroadcaster.sendTransform(cup_ar_transform)

        # # broadcast tf from camera frame to robot_ar_tag
        # #TODO check that rotation and translation values are being set to correct axis
        # robot_ar_transform = TransformStamped()
        # robot_ar_transform.header.stamp = rospy.Time.now()
        # robot_ar_transform.header.frame_id = msg.header.frame_id
        # robot_ar_transform.child_frame_id = "robot_ar_marker"
        # robot_ar_transform.transform.translation.x = robot_tvec[1]
        # robot_ar_transform.transform.translation.y = robot_tvec[0]
        # robot_ar_transform.transform.translation.z = robot_tvec[2]
        
        # q = transformations.quaternion_from_euler(robot_rvec[0], robot_rvec[2], robot_rvec[1])
        # robot_ar_transform.transform.rotation.x = q[0]
        # robot_ar_transform.transform.rotation.y = q[1]
        # robot_ar_transform.transform.rotation.z = q[2]
        # robot_ar_transform.transform.rotation.w = q[3]
        # self.tfBroadcaster.sendTransform(robot_ar_transform)
    except Exception as e:
      # print('fail to convert to ros message to cv2 image')
      print(e)



if __name__ == '__main__':
  rospy.init_node('cup_detector')
  cupDetector = ArucoDetect(1,0)

  while not rospy.is_shutdown():
    rospy.spin()

